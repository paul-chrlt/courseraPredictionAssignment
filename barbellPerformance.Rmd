---
title: "Using machine learning to measure how well are barbell performed"
author: "Paul Charlet"
date: "October 7, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

### Sources of data

We will use data from Human ActRecognition.

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
Read more: http://groupware.les.inf.puc-rio.br/har#wle_paper_section#ixzz5TG8yi6gR

### Data study

The study consists of performing Dumbbell Biceps Curl in 5 different fahions, called A to E. A is the correct fashion whereas the others are (not well) performed using different ways.
For each, the data from several sensors is recorded and stored. There is even some processed data, like maximum acceleration.

## Preliminary

We need to load the libraries and set the seed.

```{r}
library(caret)
set.seed(123)
```

## load the data

We can now download the training and testing data.

```{r}

trainingData <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",na.strings = c("NA","#DIV/0!"))

submissiontestingData <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",na.strings = c("NA","#DIV/0!"))

inTrain <- createDataPartition(trainingData$classe,p=0.75,list=FALSE)
training <- trainingData[inTrain,]
testing <- trainingData[-inTrain,]

```

## Data exploration

```{r}
dim(training)
```
We can see there are a lots of variables for the data, but the first ones are not that useful to our algorithm, and should be removed.
```{r}
head(training[,1:7])
```

There is also a lot of NAs that we should take care of. 100 columns contains more than 90% of NAs
```{r}
sum(is.na(training))
sum(complete.cases(training))
sum(colSums(is.na(training))>(.9*length(training)))
```

## preprocessing

First, we remove the unused 7 first columns, and then those with more than 90% NAs.
```{r}
training <- training[,-c(1:7)]
training <- training[,!colSums(is.na(training))>(.5*length(training))]
sum(is.na(training))
```
We now don't have any NA in our training set.

## learning

We will use a Random Forest model, which is performant for classification. For performance reasons we will limit our model to 10 trees.  
We will use 5-fold cross validation

```{r}
controlrf <- trainControl(method = "cv",5)
rfmodel <- train(classe~.,data=training,method="rf",ntree=10, trControl = controlrf)
```

## Accuracy

```{r}
rfmodel$finalModel
```
With only 10 trees, we get an OOB estimate of error rate of 3%

```{r}
confusionMatrix(testing$classe,predict(rfmodel,testing))
```
We get an accuracy of 99% in our test set. This is a performant model.

## Notes

This model allows to classify if the exercice is performed as in the experiment.  
In the case of a performance which would not be one of the prerecorded one, it would probably behave poorly. In other words, this model does not rate how well the exercice is done, but classifies how it is done between 5 possibilities.  
To get a performance rate, we would need another study with another outcome to define what is a well performed exercice.

## assignment testing

*This part is only for quiz project*

```{r}
predict(rfmodel,submissiontestingData)
```